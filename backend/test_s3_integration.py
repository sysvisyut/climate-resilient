"""
Test S3 integration and services
"""

import sys
import os
import pandas as pd
import logging
from datetime import datetime

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.utils.s3_storage import s3_storage
from app.services.data_service import data_service
from app.services.model_service import model_service

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def test_s3_storage():
    """Test basic S3 storage operations"""
    logger.info("=" * 80)
    logger.info("üß™ Testing S3 Storage Operations")
    logger.info("=" * 80)
    
    test_results = []
    
    # Test 1: CSV operations
    logger.info("\n1Ô∏è‚É£  Testing CSV operations...")
    try:
        test_df = pd.DataFrame({
            'id': [1, 2, 3],
            'value': [10, 20, 30],
            'name': ['test_a', 'test_b', 'test_c']
        })
        
        # Save
        save_success = s3_storage.save_csv_to_s3(test_df, 'test/test_data.csv')
        
        # Load
        loaded_df = s3_storage.load_csv_from_s3('test/test_data.csv')
        
        # Verify
        if loaded_df is not None and len(loaded_df) == 3:
            logger.info("   ‚úÖ CSV Save/Load: PASS")
            test_results.append(('CSV Operations', True))
        else:
            logger.error("   ‚ùå CSV Save/Load: FAIL")
            test_results.append(('CSV Operations', False))
        
        # Cleanup
        s3_storage.delete_object('test/test_data.csv')
        
    except Exception as e:
        logger.error(f"   ‚ùå CSV Operations: FAIL - {e}")
        test_results.append(('CSV Operations', False))
    
    # Test 2: JSON operations
    logger.info("\n2Ô∏è‚É£  Testing JSON operations...")
    try:
        test_data = {
            'key': 'value',
            'number': 42,
            'list': [1, 2, 3],
            'nested': {'a': 1, 'b': 2}
        }
        
        # Save
        save_success = s3_storage.save_json_to_s3(test_data, 'test/test_data.json')
        
        # Load
        loaded_data = s3_storage.load_json_from_s3('test/test_data.json')
        
        # Verify
        if loaded_data and loaded_data.get('number') == 42:
            logger.info("   ‚úÖ JSON Save/Load: PASS")
            test_results.append(('JSON Operations', True))
        else:
            logger.error("   ‚ùå JSON Save/Load: FAIL")
            test_results.append(('JSON Operations', False))
        
        # Cleanup
        s3_storage.delete_object('test/test_data.json')
        
    except Exception as e:
        logger.error(f"   ‚ùå JSON Operations: FAIL - {e}")
        test_results.append(('JSON Operations', False))
    
    # Test 3: Object existence check
    logger.info("\n3Ô∏è‚É£  Testing object existence check...")
    try:
        # Create a test file
        s3_storage.save_json_to_s3({'test': 'data'}, 'test/exists_test.json')
        
        exists = s3_storage.object_exists('test/exists_test.json')
        not_exists = not s3_storage.object_exists('test/nonexistent.json')
        
        if exists and not_exists:
            logger.info("   ‚úÖ Object Existence Check: PASS")
            test_results.append(('Object Existence', True))
        else:
            logger.error("   ‚ùå Object Existence Check: FAIL")
            test_results.append(('Object Existence', False))
        
        # Cleanup
        s3_storage.delete_object('test/exists_test.json')
        
    except Exception as e:
        logger.error(f"   ‚ùå Object Existence Check: FAIL - {e}")
        test_results.append(('Object Existence', False))
    
    # Test 4: List objects
    logger.info("\n4Ô∏è‚É£  Testing list objects...")
    try:
        # Create some test files
        for i in range(3):
            s3_storage.save_json_to_s3({'id': i}, f'test/list_test_{i}.json')
        
        objects = s3_storage.list_objects('test/list_test_')
        
        if len(objects) >= 3:
            logger.info(f"   ‚úÖ List Objects: PASS (found {len(objects)} objects)")
            test_results.append(('List Objects', True))
        else:
            logger.error(f"   ‚ùå List Objects: FAIL (found {len(objects)} objects)")
            test_results.append(('List Objects', False))
        
        # Cleanup
        for obj in objects:
            s3_storage.delete_object(obj)
        
    except Exception as e:
        logger.error(f"   ‚ùå List Objects: FAIL - {e}")
        test_results.append(('List Objects', False))
    
    return test_results


def test_data_service():
    """Test data service with S3"""
    logger.info("\n" + "=" * 80)
    logger.info("üß™ Testing Data Service")
    logger.info("=" * 80)
    
    test_results = []
    
    # Test 1: Load climate data
    logger.info("\n1Ô∏è‚É£  Testing climate data loading...")
    try:
        climate_df = data_service.load_climate_data()
        
        if climate_df is not None and len(climate_df) > 0:
            logger.info(f"   ‚úÖ Load Climate Data: PASS ({len(climate_df)} rows)")
            test_results.append(('Load Climate Data', True))
        else:
            logger.error("   ‚ùå Load Climate Data: FAIL (No data or empty)")
            test_results.append(('Load Climate Data', False))
            
    except Exception as e:
        logger.error(f"   ‚ùå Load Climate Data: FAIL - {e}")
        test_results.append(('Load Climate Data', False))
    
    # Test 2: Load health data
    logger.info("\n2Ô∏è‚É£  Testing health data loading...")
    try:
        health_df = data_service.load_health_data()
        
        if health_df is not None and len(health_df) > 0:
            logger.info(f"   ‚úÖ Load Health Data: PASS ({len(health_df)} rows)")
            test_results.append(('Load Health Data', True))
        else:
            logger.error("   ‚ùå Load Health Data: FAIL (No data or empty)")
            test_results.append(('Load Health Data', False))
            
    except Exception as e:
        logger.error(f"   ‚ùå Load Health Data: FAIL - {e}")
        test_results.append(('Load Health Data', False))
    
    # Test 3: Load locations
    logger.info("\n3Ô∏è‚É£  Testing locations data loading...")
    try:
        locations_df = data_service.load_locations()
        
        if locations_df is not None and len(locations_df) > 0:
            logger.info(f"   ‚úÖ Load Locations: PASS ({len(locations_df)} rows)")
            test_results.append(('Load Locations', True))
        else:
            logger.error("   ‚ùå Load Locations: FAIL (No data or empty)")
            test_results.append(('Load Locations', False))
            
    except Exception as e:
        logger.error(f"   ‚ùå Load Locations: FAIL - {e}")
        test_results.append(('Load Locations', False))
    
    # Test 4: Load hospital data
    logger.info("\n4Ô∏è‚É£  Testing hospital data loading...")
    try:
        hospital_df = data_service.load_hospital_data()
        
        if hospital_df is not None and len(hospital_df) > 0:
            logger.info(f"   ‚úÖ Load Hospital Data: PASS ({len(hospital_df)} rows)")
            test_results.append(('Load Hospital Data', True))
        else:
            logger.error("   ‚ùå Load Hospital Data: FAIL (No data or empty)")
            test_results.append(('Load Hospital Data', False))
            
    except Exception as e:
        logger.error(f"   ‚ùå Load Hospital Data: FAIL - {e}")
        test_results.append(('Load Hospital Data', False))
    
    # Test 5: Save and load predictions
    logger.info("\n5Ô∏è‚É£  Testing predictions save/load...")
    try:
        test_predictions = [
            {'location': 'KA', 'risk': 0.75, 'condition': 'heat_stroke'},
            {'location': 'MH', 'risk': 0.65, 'condition': 'dengue'}
        ]
        
        date = datetime.now().strftime('%Y-%m-%d')
        save_success = data_service.save_predictions(test_predictions, date)
        
        if save_success:
            logger.info("   ‚úÖ Save Predictions: PASS")
            test_results.append(('Save Predictions', True))
        else:
            logger.error("   ‚ùå Save Predictions: FAIL")
            test_results.append(('Save Predictions', False))
            
    except Exception as e:
        logger.error(f"   ‚ùå Save Predictions: FAIL - {e}")
        test_results.append(('Save Predictions', False))
    
    # Test 6: Get storage stats
    logger.info("\n6Ô∏è‚É£  Testing storage statistics...")
    try:
        stats = data_service.get_storage_stats()
        
        if stats and 'raw_data' in stats:
            logger.info("   ‚úÖ Storage Statistics: PASS")
            logger.info(f"      Raw Data: {stats['raw_data'].get('total_objects', 0)} objects")
            logger.info(f"      Processed Data: {stats['processed_data'].get('total_objects', 0)} objects")
            logger.info(f"      Models: {stats['models'].get('total_objects', 0)} objects")
            test_results.append(('Storage Statistics', True))
        else:
            logger.error("   ‚ùå Storage Statistics: FAIL")
            test_results.append(('Storage Statistics', False))
            
    except Exception as e:
        logger.error(f"   ‚ùå Storage Statistics: FAIL - {e}")
        test_results.append(('Storage Statistics', False))
    
    return test_results


def test_model_service():
    """Test model service with S3"""
    logger.info("\n" + "=" * 80)
    logger.info("üß™ Testing Model Service")
    logger.info("=" * 80)
    
    test_results = []
    
    # Test 1: List available models
    logger.info("\n1Ô∏è‚É£  Testing list available models...")
    try:
        models = model_service.list_available_models()
        
        logger.info(f"   Found {len(models)} model(s):")
        for model in models:
            logger.info(f"      - {model}")
        
        logger.info("   ‚úÖ List Models: PASS")
        test_results.append(('List Models', True))
        
    except Exception as e:
        logger.error(f"   ‚ùå List Models: FAIL - {e}")
        test_results.append(('List Models', False))
    
    # Test 2: Check if models exist
    logger.info("\n2Ô∏è‚É£  Testing model existence check...")
    try:
        risk_exists = model_service.model_exists('enhanced_risk_model.pkl')
        forecast_exists = model_service.model_exists('enhanced_forecast_model.pkl')
        
        logger.info(f"   Risk Model Exists: {risk_exists}")
        logger.info(f"   Forecast Model Exists: {forecast_exists}")
        
        if risk_exists or forecast_exists:
            logger.info("   ‚úÖ Model Existence Check: PASS")
            test_results.append(('Model Existence', True))
        else:
            logger.warning("   ‚ö†Ô∏è  Model Existence Check: PASS (no models found)")
            test_results.append(('Model Existence', True))
        
    except Exception as e:
        logger.error(f"   ‚ùå Model Existence Check: FAIL - {e}")
        test_results.append(('Model Existence', False))
    
    # Test 3: Try loading models
    logger.info("\n3Ô∏è‚É£  Testing model loading...")
    try:
        risk_model = model_service.load_risk_model()
        
        if risk_model is not None:
            logger.info("   ‚úÖ Load Risk Model: PASS")
            test_results.append(('Load Risk Model', True))
        else:
            logger.warning("   ‚ö†Ô∏è  Load Risk Model: Model not found (run save_enhanced_models.py first)")
            test_results.append(('Load Risk Model', False))
            
    except Exception as e:
        logger.error(f"   ‚ùå Load Risk Model: FAIL - {e}")
        test_results.append(('Load Risk Model', False))
    
    try:
        forecast_model = model_service.load_forecast_model()
        
        if forecast_model is not None:
            logger.info("   ‚úÖ Load Forecast Model: PASS")
            test_results.append(('Load Forecast Model', True))
        else:
            logger.warning("   ‚ö†Ô∏è  Load Forecast Model: Model not found")
            test_results.append(('Load Forecast Model', False))
            
    except Exception as e:
        logger.error(f"   ‚ùå Load Forecast Model: FAIL - {e}")
        test_results.append(('Load Forecast Model', False))
    
    try:
        scaler = model_service.load_scaler()
        
        if scaler is not None:
            logger.info("   ‚úÖ Load Scaler: PASS")
            test_results.append(('Load Scaler', True))
        else:
            logger.warning("   ‚ö†Ô∏è  Load Scaler: Scaler not found")
            test_results.append(('Load Scaler', False))
            
    except Exception as e:
        logger.error(f"   ‚ùå Load Scaler: FAIL - {e}")
        test_results.append(('Load Scaler', False))
    
    return test_results


def print_summary(all_results):
    """Print test summary"""
    logger.info("\n" + "=" * 80)
    logger.info("üìä TEST SUMMARY")
    logger.info("=" * 80)
    
    total_tests = len(all_results)
    passed_tests = sum(1 for _, result in all_results if result)
    failed_tests = total_tests - passed_tests
    
    logger.info(f"\nTotal Tests: {total_tests}")
    logger.info(f"‚úÖ Passed: {passed_tests}")
    logger.info(f"‚ùå Failed: {failed_tests}")
    logger.info(f"Success Rate: {(passed_tests/total_tests*100):.1f}%")
    
    logger.info("\nDetailed Results:")
    for test_name, result in all_results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        logger.info(f"   {status}: {test_name}")
    
    if failed_tests == 0:
        logger.info("\nüéâ All tests passed! S3 integration is working correctly.")
        logger.info("\nüí° Next Steps:")
        logger.info("   1. Update your application to use data_service and model_service")
        logger.info("   2. Test with your actual application endpoints")
        logger.info("   3. Monitor AWS CloudWatch for any issues")
    else:
        logger.info(f"\n‚ö†Ô∏è  {failed_tests} test(s) failed. Please review the logs above.")
        logger.info("\nüí° Troubleshooting:")
        logger.info("   1. Verify AWS credentials are configured correctly")
        logger.info("   2. Check bucket names in s3_storage.py match your S3 buckets")
        logger.info("   3. Ensure data files exist before running tests")
        logger.info("   4. Run migrate_data_to_s3.py to upload data to S3")


def main():
    """Run all tests"""
    logger.info("\n" + "üöÄ" * 40)
    logger.info("   S3 Integration Test Suite")
    logger.info("üöÄ" * 40 + "\n")
    
    all_results = []
    
    # Run tests
    all_results.extend(test_s3_storage())
    all_results.extend(test_data_service())
    all_results.extend(test_model_service())
    
    # Print summary
    print_summary(all_results)
    
    logger.info("\n" + "=" * 80)


if __name__ == "__main__":
    main()
